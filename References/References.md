# References

1. [Attention is All You Need](https://arxiv.org/abs/1706.03762)
2. [GloVe: Global Vectors for Word Representation](https://nlp.stanford.edu/pubs/glove.pdf)
3. [Efficient Estimation of Word Representations in Vector Space](https://arxiv.org/pdf/1301.3781.pdf)
4. [XGBoost: A Scalable Tree Boosting System](https://arxiv.org/pdf/1603.02754.pdf)
5. [A comprehensive review of Binary Neural Network] (https://arxiv.org/pdf/2110.06804.pdf)


See [a more complete list](https://github.com/daturkel/learning-papers)
