# References

1. [Attention is All You Need](https://arxiv.org/abs/1706.03762)
2. [GloVe: Global Vectors for Word Representation](https://nlp.stanford.edu/pubs/glove.pdf)
3. [Efficient Estimation of Word Representations in Vector Space](https://arxiv.org/pdf/1301.3781.pdf)
4. [XGBoost: A Scalable Tree Boosting System](https://arxiv.org/pdf/1603.02754.pdf)
5. [A comprehensive review of Binary Neural Network](https://arxiv.org/pdf/2110.06804.pdf)
6. LeNet: [Gradient-Based Learning Applied to Document Recognition](http://vision.stanford.edu/cs598_spring07/papers/Lecun98.pdf)
7. AlexNet: [ImageNet Classification with Deep Convolutional
Neural Networks](https://proceedings.neurips.cc/paper_files/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf)


See [a more complete list](https://github.com/daturkel/learning-papers)
