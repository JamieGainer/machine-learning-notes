{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a76188aa",
   "metadata": {},
   "source": [
    "# Neural Network Implementation in Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67c1b5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7143a18",
   "metadata": {},
   "source": [
    "Method to initialize weights and biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8161c5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights_and_biases(layer_dim_list):\n",
    "    W, b = [], []\n",
    "    for layer1, layer2 in zip(layer_dim_list, layer_dim_list[1:]):\n",
    "        W.append(np.random.randn(layer1, layer2) * 0.01)\n",
    "        b.append(np.zeros((1, layer2)))\n",
    "    return {\"W_i\": W, \"b_i\": b}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2fd64e8",
   "metadata": {},
   "source": [
    "Method to initialize activation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "99bf9850",
   "metadata": {},
   "outputs": [],
   "source": [
    "relu = {\"f\": lambda x: np.where(x > 0, x, 0),\n",
    "        \"f_prime\": lambda x: np.where(x > 0, 1, 0)}\n",
    "\n",
    "sigmoid = {\"f\": lambda x: 1.0 / (1.0 + np.exp(x)),\n",
    "           \"f_prime\": lambda x: -np.exp(x)/(1.0 + np.exp(x))**2}\n",
    "    \n",
    "def relu_except_last_layer(layer_dim_list):\n",
    "    return {\"f\": [relu[\"f\"]] * (len(layer_dim_list) - 2) + [sigmoid[\"f\"]],\n",
    "            \"f_prime\": [relu[\"f_prime\"]] * (len(layer_dim_list) - 2) + [sigmoid[\"f_prime\"]]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8460564",
   "metadata": {},
   "source": [
    "Method for forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f9b0f477",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_pass(X, W_i, b_i, g_i):\n",
    "    Z, A = [], [X]\n",
    "    for W, b, g in zip(W_i, b_i, g_i):\n",
    "        Z.append(A[-1].dot(W) + b)\n",
    "        A.append(g(Z[-1]))\n",
    "    return {\"Z_i\": Z, \"A_i\": A}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f12f87",
   "metadata": {},
   "source": [
    "Methods for loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "62dc5686",
   "metadata": {},
   "outputs": [],
   "source": [
    "ssr = {\"f\": lambda A, Y: (1.0)/len(Y) * np.sum((A - Y) * (A - Y)),\n",
    "       \"f_prime\": lambda A, Y: (2.0)/len(Y) * np.sum(A - Y)}\n",
    "\n",
    "ce = {\"f\": lambda A, Y: (1.0)/len(Y) * np.sum(Y * np.log(A) + (1 - Y) * np.log(1 - A)),\n",
    "      \"f_prime\": lambda A, Y: (1.0)/len(Y) * np.sum(Y/A - (1 - Y)/(1 - A))}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c23abb0",
   "metadata": {},
   "source": [
    "Method for backward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a91b08df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backwards_pass(loss_derivative, Y, g_prime_i, A_i, Z_i):\n",
    "    dW, db = [], []\n",
    "    deriv = (loss_derivative(A_i[-1], Y) * g_prime_i[-1](A_i[-1])).transpose()\n",
    "    i = 0\n",
    "    print(len(g_prime_i), len(A_i))\n",
    "    for gp, A in zip(reversed(g_prime_i[:-2]), reversed(A_i[:-2])):\n",
    "        print(i)\n",
    "        i += 1\n",
    "        print(A.shape)\n",
    "        dW.append(np.sum(deriv.dot(A), axis=0))\n",
    "        db.append(np.sum(deriv, axis=0))\n",
    "        deriv = deriv.dot(gp(A))\n",
    "    return {\"dW_i\": list(reversed(dW)), \"db_i\": list(reversed(db))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0cb6af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7d6409c0",
   "metadata": {},
   "source": [
    "## Example Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "00bd89f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 4\n",
      "0\n",
      "(50, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'dW_i': [array([-2.06138991e-05, -3.57051326e-05, -2.48096345e-05, -8.06338827e-06,\n",
       "         -3.79843978e-05, -1.53468167e-05, -3.42723164e-05, -5.15541083e-05,\n",
       "         -1.47764021e-05, -1.42483664e-05])],\n",
       " 'db_i': [array([-7.87738936e-05, -7.87739079e-05, -7.87739657e-05, -7.87739243e-05,\n",
       "         -7.87739427e-05, -7.87739025e-05, -7.87739164e-05, -7.87739229e-05,\n",
       "         -7.87739352e-05, -7.87738915e-05, -7.87739185e-05, -7.87739211e-05,\n",
       "         -7.87739222e-05, -7.87739307e-05, -7.87738843e-05, -7.87739907e-05,\n",
       "         -7.87739246e-05, -7.87739396e-05, -7.87739732e-05, -7.87739353e-05,\n",
       "         -7.87739251e-05, -7.87739091e-05, -7.87739483e-05, -7.87739371e-05,\n",
       "         -7.87739595e-05, -7.87739510e-05, -7.87739493e-05, -7.87739136e-05,\n",
       "         -7.87739660e-05, -7.87739800e-05, -7.87739505e-05, -7.87738991e-05,\n",
       "         -7.87739151e-05, -7.87739431e-05, -7.87739138e-05, -7.87739460e-05,\n",
       "         -7.87739259e-05, -7.87739436e-05, -7.87739247e-05, -7.87739772e-05,\n",
       "         -7.87739307e-05, -7.87739637e-05, -7.87739617e-05, -7.87739412e-05,\n",
       "         -7.87740140e-05, -7.87739361e-05, -7.87738992e-05, -7.87739301e-05,\n",
       "         -7.87739507e-05, -7.87739670e-05])]}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_of_samples = 50\n",
    "layers = [2, 10, 5, 1]\n",
    "\n",
    "X = np.random.randn(number_of_samples, layers[0])\n",
    "Y = np.array([1] * (number_of_samples // 2) + [0] * (number_of_samples - number_of_samples // 2))\n",
    "\n",
    "\n",
    "weights_and_biases = initialize_weights_and_biases(layers)\n",
    "W_i, b_i = [weights_and_biases[_] for _ in [\"W_i\", \"b_i\"]]\n",
    "\n",
    "g_i = relu_except_last_layer(layers)[\"f\"]\n",
    "\n",
    "forward_pass_values = forward_pass(X, W_i, b_i, g_i)\n",
    "Z_i, A_i = [forward_pass_values[_] for _ in [\"Z_i\", \"A_i\"]]\n",
    "\n",
    "g_prime_i = relu_except_last_layer(layers)[\"f_prime\"]\n",
    "backwards_pass(ce[\"f_prime\"], Y, g_prime_i, A_i, Z_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2284717d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
