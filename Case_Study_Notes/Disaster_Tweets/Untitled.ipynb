{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc8d0691",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-18 15:45:56.954908: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import keras_nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fff6c43f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c79da54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aac85120",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13456dad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification_Metrics.md             Untitled.ipynb\r\n",
      "CountVectorizer.ipynb                 \u001b[34mnlp-getting-started\u001b[m\u001b[m\r\n",
      "Disaster_Tweets_with_TensorFlow.ipynb train_test_split.ipynb\r\n",
      "NLP.md\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ee31472",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv_df = pd.read_csv(\"nlp-getting-started/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84000e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, validation_df = train_test_split(train_csv_df, train_size=0.85, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc41cd82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6406</th>\n",
       "      <td>9157</td>\n",
       "      <td>suicide%20bomber</td>\n",
       "      <td>NaN</td>\n",
       "      <td>News: 'Islamic State claims suicide bombing at...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2774</th>\n",
       "      <td>3990</td>\n",
       "      <td>devastation</td>\n",
       "      <td>Denver, CO</td>\n",
       "      <td>$10M SETTLEMENT attained using our illustratio...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5050</th>\n",
       "      <td>7198</td>\n",
       "      <td>natural%20disaster</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>On the sneak America has us spoiled. A natural...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1851</th>\n",
       "      <td>2661</td>\n",
       "      <td>crush</td>\n",
       "      <td>Cleveland, Ohio</td>\n",
       "      <td>My woman crush wedneday goes to the beautiful ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2320</th>\n",
       "      <td>3336</td>\n",
       "      <td>demolished</td>\n",
       "      <td>Dublin, Ireland</td>\n",
       "      <td>Home2 Suites offices are coming to Salvi's Bis...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4192</th>\n",
       "      <td>5955</td>\n",
       "      <td>hazard</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>CONFIRMED: Sanchez Hazard and Bolasie will be ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5190</th>\n",
       "      <td>7410</td>\n",
       "      <td>obliterated</td>\n",
       "      <td>Tennessee</td>\n",
       "      <td>WACKOES like #MicheleBachman predict the WORLD...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6948</th>\n",
       "      <td>9967</td>\n",
       "      <td>tsunami</td>\n",
       "      <td>NaN</td>\n",
       "      <td>she keep it wet like tsunami.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>623</th>\n",
       "      <td>896</td>\n",
       "      <td>bioterrorism</td>\n",
       "      <td>Philadelphia, PA</td>\n",
       "      <td>@MeyerBjoern @thelonevirologi @MackayIM of a m...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5211</th>\n",
       "      <td>7443</td>\n",
       "      <td>obliterated</td>\n",
       "      <td>don't buy the s*n</td>\n",
       "      <td>Just absolutely obliterated a moth my new purc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id             keyword           location  \\\n",
       "6406  9157    suicide%20bomber                NaN   \n",
       "2774  3990         devastation         Denver, CO   \n",
       "5050  7198  natural%20disaster        Los Angeles   \n",
       "1851  2661               crush    Cleveland, Ohio   \n",
       "2320  3336          demolished    Dublin, Ireland   \n",
       "4192  5955              hazard            Chicago   \n",
       "5190  7410         obliterated          Tennessee   \n",
       "6948  9967             tsunami                NaN   \n",
       "623    896        bioterrorism   Philadelphia, PA   \n",
       "5211  7443         obliterated  don't buy the s*n   \n",
       "\n",
       "                                                   text  target  \n",
       "6406  News: 'Islamic State claims suicide bombing at...       1  \n",
       "2774  $10M SETTLEMENT attained using our illustratio...       1  \n",
       "5050  On the sneak America has us spoiled. A natural...       1  \n",
       "1851  My woman crush wedneday goes to the beautiful ...       0  \n",
       "2320  Home2 Suites offices are coming to Salvi's Bis...       0  \n",
       "4192  CONFIRMED: Sanchez Hazard and Bolasie will be ...       1  \n",
       "5190  WACKOES like #MicheleBachman predict the WORLD...       0  \n",
       "6948                      she keep it wet like tsunami.       0  \n",
       "623   @MeyerBjoern @thelonevirologi @MackayIM of a m...       1  \n",
       "5211  Just absolutely obliterated a moth my new purc...       0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "536e1a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_vectorizer, keyword_vectorizer, location_vectorizer = [CountVectorizer()] * 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe45e2e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6471, 19365), (1142, 19365))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_text_word_count_vectors = text_vectorizer.fit_transform(train_df[\"text\"].fillna(\"\"))\n",
    "val_text_word_count_vectors = text_vectorizer.transform(validation_df[\"text\"].fillna(\"\"))\n",
    "train_text_word_count_vectors.shape, val_text_word_count_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "47f5cef4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6471, 239), (1142, 239))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_keyword_word_count_vectors = keyword_vectorizer.fit_transform(train_df[\"keyword\"].fillna(\"\"))\n",
    "val_keyword_word_count_vectors = keyword_vectorizer.transform(validation_df[\"keyword\"].fillna(\"\"))\n",
    "train_keyword_word_count_vectors.shape, val_keyword_word_count_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4dbc2fa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6471, 2932), (1142, 2932))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_location_word_count_vectors = location_vectorizer.fit_transform(train_df[\"location\"].fillna(\"\"))\n",
    "val_location_word_count_vectors = location_vectorizer.transform(validation_df[\"location\"].fillna(\"\"))\n",
    "train_location_word_count_vectors.shape, val_location_word_count_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af5f150a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6471, 22536)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X = np.hstack((train_keyword_word_count_vectors.todense(), \n",
    "                     train_location_word_count_vectors.todense(),\n",
    "                     train_text_word_count_vectors.todense()))\n",
    "train_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bcbb9fa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1142, 22536)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_X = np.hstack((val_keyword_word_count_vectors.todense(), \n",
    "                     val_location_word_count_vectors.todense(),\n",
    "                     val_text_word_count_vectors.todense()))\n",
    "val_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2a988f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(units=1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7f4808c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.compile(loss=tf.keras.losses.BinaryCrossentropy(), \n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[tf.keras.metrics.BinaryAccuracy(),\n",
    "                         tf.keras.metrics.BinaryCrossentropy(),\n",
    "                         tf.keras.metrics.AUC()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "92f64f21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "203/203 [==============================] - 2s 5ms/step - loss: 0.6429 - binary_accuracy: 0.7255 - binary_crossentropy: 0.6429 - auc: 0.7707 - val_loss: 0.6008 - val_binary_accuracy: 0.7522 - val_binary_crossentropy: 0.6008 - val_auc: 0.8210\n",
      "Epoch 2/50\n",
      "203/203 [==============================] - 1s 5ms/step - loss: 0.5497 - binary_accuracy: 0.8212 - binary_crossentropy: 0.5497 - auc: 0.8751 - val_loss: 0.5516 - val_binary_accuracy: 0.7688 - val_binary_crossentropy: 0.5516 - val_auc: 0.8372\n",
      "Epoch 3/50\n",
      "203/203 [==============================] - 1s 5ms/step - loss: 0.4885 - binary_accuracy: 0.8509 - binary_crossentropy: 0.4885 - auc: 0.9056 - val_loss: 0.5207 - val_binary_accuracy: 0.7820 - val_binary_crossentropy: 0.5207 - val_auc: 0.8479\n",
      "Epoch 4/50\n",
      "203/203 [==============================] - 1s 5ms/step - loss: 0.4436 - binary_accuracy: 0.8690 - binary_crossentropy: 0.4436 - auc: 0.9245 - val_loss: 0.4999 - val_binary_accuracy: 0.7933 - val_binary_crossentropy: 0.4999 - val_auc: 0.8543\n",
      "Epoch 5/50\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.4084 - binary_accuracy: 0.8822 - binary_crossentropy: 0.4084 - auc: 0.9389 - val_loss: 0.4847 - val_binary_accuracy: 0.7995 - val_binary_crossentropy: 0.4847 - val_auc: 0.8579\n",
      "Epoch 6/50\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.3794 - binary_accuracy: 0.8931 - binary_crossentropy: 0.3794 - auc: 0.9492 - val_loss: 0.4734 - val_binary_accuracy: 0.8056 - val_binary_crossentropy: 0.4734 - val_auc: 0.8604\n",
      "Epoch 7/50\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.3551 - binary_accuracy: 0.9008 - binary_crossentropy: 0.3551 - auc: 0.9561 - val_loss: 0.4647 - val_binary_accuracy: 0.8065 - val_binary_crossentropy: 0.4647 - val_auc: 0.8626\n",
      "Epoch 8/50\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.3340 - binary_accuracy: 0.9088 - binary_crossentropy: 0.3340 - auc: 0.9623 - val_loss: 0.4578 - val_binary_accuracy: 0.8056 - val_binary_crossentropy: 0.4578 - val_auc: 0.8639\n",
      "Epoch 9/50\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.3154 - binary_accuracy: 0.9139 - binary_crossentropy: 0.3154 - auc: 0.9678 - val_loss: 0.4525 - val_binary_accuracy: 0.8100 - val_binary_crossentropy: 0.4525 - val_auc: 0.8650\n",
      "Epoch 10/50\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.2988 - binary_accuracy: 0.9183 - binary_crossentropy: 0.2988 - auc: 0.9718 - val_loss: 0.4484 - val_binary_accuracy: 0.8091 - val_binary_crossentropy: 0.4484 - val_auc: 0.8655\n",
      "Epoch 11/50\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.2839 - binary_accuracy: 0.9246 - binary_crossentropy: 0.2839 - auc: 0.9754 - val_loss: 0.4447 - val_binary_accuracy: 0.8100 - val_binary_crossentropy: 0.4447 - val_auc: 0.8662\n",
      "Epoch 12/50\n",
      "203/203 [==============================] - 1s 6ms/step - loss: 0.2703 - binary_accuracy: 0.9291 - binary_crossentropy: 0.2703 - auc: 0.9783 - val_loss: 0.4421 - val_binary_accuracy: 0.8100 - val_binary_crossentropy: 0.4421 - val_auc: 0.8666\n",
      "Epoch 13/50\n",
      "203/203 [==============================] - 1s 5ms/step - loss: 0.2578 - binary_accuracy: 0.9334 - binary_crossentropy: 0.2578 - auc: 0.9810 - val_loss: 0.4400 - val_binary_accuracy: 0.8109 - val_binary_crossentropy: 0.4400 - val_auc: 0.8669\n",
      "Epoch 14/50\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.2463 - binary_accuracy: 0.9380 - binary_crossentropy: 0.2463 - auc: 0.9831 - val_loss: 0.4381 - val_binary_accuracy: 0.8109 - val_binary_crossentropy: 0.4381 - val_auc: 0.8676\n",
      "Epoch 15/50\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.2356 - binary_accuracy: 0.9425 - binary_crossentropy: 0.2356 - auc: 0.9852 - val_loss: 0.4368 - val_binary_accuracy: 0.8109 - val_binary_crossentropy: 0.4368 - val_auc: 0.8676\n",
      "Epoch 16/50\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.2256 - binary_accuracy: 0.9442 - binary_crossentropy: 0.2256 - auc: 0.9872 - val_loss: 0.4357 - val_binary_accuracy: 0.8100 - val_binary_crossentropy: 0.4357 - val_auc: 0.8676\n",
      "Epoch 17/50\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.2162 - binary_accuracy: 0.9484 - binary_crossentropy: 0.2162 - auc: 0.9887 - val_loss: 0.4348 - val_binary_accuracy: 0.8100 - val_binary_crossentropy: 0.4348 - val_auc: 0.8677\n",
      "Epoch 18/50\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.2075 - binary_accuracy: 0.9505 - binary_crossentropy: 0.2075 - auc: 0.9899 - val_loss: 0.4343 - val_binary_accuracy: 0.8126 - val_binary_crossentropy: 0.4343 - val_auc: 0.8675\n",
      "Epoch 19/50\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.1992 - binary_accuracy: 0.9533 - binary_crossentropy: 0.1992 - auc: 0.9911 - val_loss: 0.4339 - val_binary_accuracy: 0.8109 - val_binary_crossentropy: 0.4339 - val_auc: 0.8675\n",
      "Epoch 20/50\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.1915 - binary_accuracy: 0.9563 - binary_crossentropy: 0.1915 - auc: 0.9921 - val_loss: 0.4339 - val_binary_accuracy: 0.8109 - val_binary_crossentropy: 0.4339 - val_auc: 0.8674\n",
      "Epoch 21/50\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.1841 - binary_accuracy: 0.9581 - binary_crossentropy: 0.1841 - auc: 0.9931 - val_loss: 0.4341 - val_binary_accuracy: 0.8091 - val_binary_crossentropy: 0.4341 - val_auc: 0.8672\n",
      "Epoch 22/50\n",
      "203/203 [==============================] - 1s 4ms/step - loss: 0.1772 - binary_accuracy: 0.9618 - binary_crossentropy: 0.1772 - auc: 0.9940 - val_loss: 0.4345 - val_binary_accuracy: 0.8091 - val_binary_crossentropy: 0.4345 - val_auc: 0.8668\n",
      "Epoch 23/50\n",
      "203/203 [==============================] - 1s 4ms/step - loss: 0.1706 - binary_accuracy: 0.9638 - binary_crossentropy: 0.1706 - auc: 0.9946 - val_loss: 0.4349 - val_binary_accuracy: 0.8082 - val_binary_crossentropy: 0.4349 - val_auc: 0.8668\n",
      "Epoch 24/50\n",
      "203/203 [==============================] - 1s 6ms/step - loss: 0.1643 - binary_accuracy: 0.9654 - binary_crossentropy: 0.1643 - auc: 0.9952 - val_loss: 0.4351 - val_binary_accuracy: 0.8082 - val_binary_crossentropy: 0.4351 - val_auc: 0.8668\n",
      "Epoch 25/50\n",
      "203/203 [==============================] - 1s 5ms/step - loss: 0.1584 - binary_accuracy: 0.9669 - binary_crossentropy: 0.1584 - auc: 0.9957 - val_loss: 0.4358 - val_binary_accuracy: 0.8100 - val_binary_crossentropy: 0.4358 - val_auc: 0.8665\n",
      "Epoch 26/50\n",
      "203/203 [==============================] - 1s 4ms/step - loss: 0.1527 - binary_accuracy: 0.9683 - binary_crossentropy: 0.1527 - auc: 0.9962 - val_loss: 0.4364 - val_binary_accuracy: 0.8074 - val_binary_crossentropy: 0.4364 - val_auc: 0.8662\n",
      "Epoch 27/50\n",
      "203/203 [==============================] - 1s 4ms/step - loss: 0.1473 - binary_accuracy: 0.9713 - binary_crossentropy: 0.1473 - auc: 0.9967 - val_loss: 0.4376 - val_binary_accuracy: 0.8091 - val_binary_crossentropy: 0.4376 - val_auc: 0.8654\n",
      "Epoch 28/50\n",
      "203/203 [==============================] - 1s 7ms/step - loss: 0.1422 - binary_accuracy: 0.9725 - binary_crossentropy: 0.1422 - auc: 0.9970 - val_loss: 0.4384 - val_binary_accuracy: 0.8056 - val_binary_crossentropy: 0.4384 - val_auc: 0.8651\n",
      "Epoch 29/50\n",
      "203/203 [==============================] - 1s 5ms/step - loss: 0.1373 - binary_accuracy: 0.9733 - binary_crossentropy: 0.1373 - auc: 0.9973 - val_loss: 0.4393 - val_binary_accuracy: 0.8056 - val_binary_crossentropy: 0.4393 - val_auc: 0.8650\n",
      "Epoch 30/50\n",
      "203/203 [==============================] - 2s 8ms/step - loss: 0.1326 - binary_accuracy: 0.9747 - binary_crossentropy: 0.1326 - auc: 0.9976 - val_loss: 0.4407 - val_binary_accuracy: 0.7995 - val_binary_crossentropy: 0.4407 - val_auc: 0.8644\n",
      "Epoch 31/50\n",
      "203/203 [==============================] - 1s 7ms/step - loss: 0.1281 - binary_accuracy: 0.9753 - binary_crossentropy: 0.1281 - auc: 0.9979 - val_loss: 0.4416 - val_binary_accuracy: 0.7986 - val_binary_crossentropy: 0.4416 - val_auc: 0.8642\n",
      "Epoch 32/50\n",
      "203/203 [==============================] - 1s 4ms/step - loss: 0.1238 - binary_accuracy: 0.9765 - binary_crossentropy: 0.1238 - auc: 0.9981 - val_loss: 0.4429 - val_binary_accuracy: 0.8012 - val_binary_crossentropy: 0.4429 - val_auc: 0.8639\n",
      "Epoch 33/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "203/203 [==============================] - 1s 4ms/step - loss: 0.1197 - binary_accuracy: 0.9770 - binary_crossentropy: 0.1197 - auc: 0.9983 - val_loss: 0.4445 - val_binary_accuracy: 0.8004 - val_binary_crossentropy: 0.4445 - val_auc: 0.8634\n",
      "Epoch 34/50\n",
      "203/203 [==============================] - 1s 5ms/step - loss: 0.1158 - binary_accuracy: 0.9785 - binary_crossentropy: 0.1158 - auc: 0.9985 - val_loss: 0.4456 - val_binary_accuracy: 0.8004 - val_binary_crossentropy: 0.4456 - val_auc: 0.8631\n",
      "Epoch 35/50\n",
      "203/203 [==============================] - 1s 6ms/step - loss: 0.1121 - binary_accuracy: 0.9791 - binary_crossentropy: 0.1121 - auc: 0.9986 - val_loss: 0.4474 - val_binary_accuracy: 0.7986 - val_binary_crossentropy: 0.4474 - val_auc: 0.8627\n",
      "Epoch 36/50\n",
      "203/203 [==============================] - 1s 6ms/step - loss: 0.1084 - binary_accuracy: 0.9805 - binary_crossentropy: 0.1084 - auc: 0.9988 - val_loss: 0.4486 - val_binary_accuracy: 0.7986 - val_binary_crossentropy: 0.4486 - val_auc: 0.8626\n",
      "Epoch 37/50\n",
      "203/203 [==============================] - 1s 6ms/step - loss: 0.1050 - binary_accuracy: 0.9816 - binary_crossentropy: 0.1050 - auc: 0.9989 - val_loss: 0.4502 - val_binary_accuracy: 0.7977 - val_binary_crossentropy: 0.4502 - val_auc: 0.8622\n",
      "Epoch 38/50\n",
      "203/203 [==============================] - 1s 6ms/step - loss: 0.1017 - binary_accuracy: 0.9819 - binary_crossentropy: 0.1017 - auc: 0.9990 - val_loss: 0.4516 - val_binary_accuracy: 0.7986 - val_binary_crossentropy: 0.4516 - val_auc: 0.8618\n",
      "Epoch 39/50\n",
      "203/203 [==============================] - 1s 4ms/step - loss: 0.0985 - binary_accuracy: 0.9825 - binary_crossentropy: 0.0985 - auc: 0.9991 - val_loss: 0.4534 - val_binary_accuracy: 0.7977 - val_binary_crossentropy: 0.4534 - val_auc: 0.8612\n",
      "Epoch 40/50\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0955 - binary_accuracy: 0.9835 - binary_crossentropy: 0.0955 - auc: 0.9992 - val_loss: 0.4549 - val_binary_accuracy: 0.7951 - val_binary_crossentropy: 0.4549 - val_auc: 0.8611\n",
      "Epoch 41/50\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0925 - binary_accuracy: 0.9847 - binary_crossentropy: 0.0925 - auc: 0.9992 - val_loss: 0.4565 - val_binary_accuracy: 0.7968 - val_binary_crossentropy: 0.4565 - val_auc: 0.8607\n",
      "Epoch 42/50\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0897 - binary_accuracy: 0.9853 - binary_crossentropy: 0.0897 - auc: 0.9993 - val_loss: 0.4585 - val_binary_accuracy: 0.7933 - val_binary_crossentropy: 0.4585 - val_auc: 0.8605\n",
      "Epoch 43/50\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0870 - binary_accuracy: 0.9861 - binary_crossentropy: 0.0870 - auc: 0.9994 - val_loss: 0.4602 - val_binary_accuracy: 0.7942 - val_binary_crossentropy: 0.4602 - val_auc: 0.8599\n",
      "Epoch 44/50\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0844 - binary_accuracy: 0.9862 - binary_crossentropy: 0.0844 - auc: 0.9994 - val_loss: 0.4625 - val_binary_accuracy: 0.7951 - val_binary_crossentropy: 0.4625 - val_auc: 0.8596\n",
      "Epoch 45/50\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0819 - binary_accuracy: 0.9867 - binary_crossentropy: 0.0819 - auc: 0.9995 - val_loss: 0.4643 - val_binary_accuracy: 0.7951 - val_binary_crossentropy: 0.4643 - val_auc: 0.8591\n",
      "Epoch 46/50\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0795 - binary_accuracy: 0.9872 - binary_crossentropy: 0.0795 - auc: 0.9995 - val_loss: 0.4663 - val_binary_accuracy: 0.7942 - val_binary_crossentropy: 0.4663 - val_auc: 0.8587\n",
      "Epoch 47/50\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0772 - binary_accuracy: 0.9876 - binary_crossentropy: 0.0772 - auc: 0.9996 - val_loss: 0.4683 - val_binary_accuracy: 0.7916 - val_binary_crossentropy: 0.4683 - val_auc: 0.8582\n",
      "Epoch 48/50\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0750 - binary_accuracy: 0.9878 - binary_crossentropy: 0.0750 - auc: 0.9996 - val_loss: 0.4703 - val_binary_accuracy: 0.7898 - val_binary_crossentropy: 0.4703 - val_auc: 0.8579\n",
      "Epoch 49/50\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0728 - binary_accuracy: 0.9881 - binary_crossentropy: 0.0728 - auc: 0.9996 - val_loss: 0.4727 - val_binary_accuracy: 0.7942 - val_binary_crossentropy: 0.4727 - val_auc: 0.8571\n",
      "Epoch 50/50\n",
      "203/203 [==============================] - 1s 3ms/step - loss: 0.0708 - binary_accuracy: 0.9889 - binary_crossentropy: 0.0708 - auc: 0.9997 - val_loss: 0.4749 - val_binary_accuracy: 0.7925 - val_binary_crossentropy: 0.4749 - val_auc: 0.8567\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f83b6708f10>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1.fit(x=train_X, y=train_df[\"target\"], epochs=50, \n",
    "            validation_data=(val_X, validation_df[\"target\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cda792a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ddb6dde9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/keras-nlp/models/bert_tiny_en_uncased/v1/model.h5\n",
      "17602216/17602216 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e3902fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_tokenizer = keras_nlp.models.BertTokenizer.from_preset(\"bert_tiny_en_uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9966f87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_BERT_preprocessor = keras_nlp.models.BertPreprocessor(text_tokenizer, sequence_length=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bd696b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_BERT_input = text_BERT_preprocessor(x=train_df[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c06a35c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_BERT_input = text_BERT_preprocessor(x=validation_df[\"text\"], y=validation_df[\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "498e0c50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'token_ids': <tf.Tensor: shape=(6471, 64), dtype=int32, numpy=\n",
       "  array([[  101,  2739,  1024, ...,     0,     0,     0],\n",
       "         [  101,  1002,  2184, ...,     0,     0,     0],\n",
       "         [  101,  2006,  1996, ...,     0,     0,     0],\n",
       "         ...,\n",
       "         [  101, 19183,  9451, ...,     0,     0,     0],\n",
       "         [  101,  2074,  3294, ...,     0,     0,     0],\n",
       "         [  101,  6168, 15333, ...,     0,     0,     0]], dtype=int32)>,\n",
       "  'segment_ids': <tf.Tensor: shape=(6471, 64), dtype=int32, numpy=\n",
       "  array([[0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0],\n",
       "         [0, 0, 0, ..., 0, 0, 0]], dtype=int32)>,\n",
       "  'padding_mask': <tf.Tensor: shape=(6471, 64), dtype=bool, numpy=\n",
       "  array([[ True,  True,  True, ..., False, False, False],\n",
       "         [ True,  True,  True, ..., False, False, False],\n",
       "         [ True,  True,  True, ..., False, False, False],\n",
       "         ...,\n",
       "         [ True,  True,  True, ..., False, False, False],\n",
       "         [ True,  True,  True, ..., False, False, False],\n",
       "         [ True,  True,  True, ..., False, False, False]])>},\n",
       " 6406    1\n",
       " 2774    1\n",
       " 5050    1\n",
       " 1851    0\n",
       " 2320    0\n",
       "        ..\n",
       " 905     0\n",
       " 5192    0\n",
       " 3980    1\n",
       " 235     0\n",
       " 5157    1\n",
       " Name: target, Length: 6471, dtype: int64)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_BERT_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3933f46d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655446ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/keras-nlp/models/albert_base_en_uncased/v1/vocab.spm\n",
      "760289/760289 [==============================] - 0s 0us/step\n",
      "Downloading data from https://storage.googleapis.com/keras-nlp/models/albert_base_en_uncased/v1/model.h5\n",
      "46778848/46778848 [==============================] - 1s 0us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-18 16:50:24.563014: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'albert_preprocessor/multi_segment_packer_4/Trimmer/Trim/RoundRobinTrimmer/generate_mask/while/Tile/multiples/albert_preprocessor/multi_segment_packer_4/Trimmer/Trim/RoundRobinTrimmer/generate_mask/strided_slice' with dtype int32\n",
      "\t [[{{node albert_preprocessor/multi_segment_packer_4/Trimmer/Trim/RoundRobinTrimmer/generate_mask/while/Tile/multiples/albert_preprocessor/multi_segment_packer_4/Trimmer/Trim/RoundRobinTrimmer/generate_mask/strided_slice}}]]\n",
      "2023-06-18 16:50:24.566667: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'albert_preprocessor/multi_segment_packer_4/Trimmer/Trim/RoundRobinTrimmer/generate_mask/while/Tile/multiples/albert_preprocessor/multi_segment_packer_4/Trimmer/Trim/RoundRobinTrimmer/generate_mask/strided_slice' with dtype int32\n",
      "\t [[{{node albert_preprocessor/multi_segment_packer_4/Trimmer/Trim/RoundRobinTrimmer/generate_mask/while/Tile/multiples/albert_preprocessor/multi_segment_packer_4/Trimmer/Trim/RoundRobinTrimmer/generate_mask/strided_slice}}]]\n",
      "2023-06-18 16:50:24.569078: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'albert_preprocessor/multi_segment_packer_4/Trimmer/Trim/RoundRobinTrimmer/generate_mask/while/Tile/multiples/albert_preprocessor/multi_segment_packer_4/Trimmer/Trim/RoundRobinTrimmer/generate_mask/strided_slice' with dtype int32\n",
      "\t [[{{node albert_preprocessor/multi_segment_packer_4/Trimmer/Trim/RoundRobinTrimmer/generate_mask/while/Tile/multiples/albert_preprocessor/multi_segment_packer_4/Trimmer/Trim/RoundRobinTrimmer/generate_mask/strided_slice}}]]\n",
      "2023-06-18 16:50:25.268484: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [6471]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-06-18 16:50:25.268763: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_6' with dtype resource\n",
      "\t [[{{node Placeholder/_6}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    }
   ],
   "source": [
    "tiny_classifier = keras_nlp.models.AlbertClassifier.from_preset(\n",
    "    \"albert_base_en_uncased\",\n",
    "    num_classes=2,\n",
    ")\n",
    "\n",
    "tiny_classifier.fit(\n",
    "    x=train_df[\"text\"],\n",
    "    y=train_df[\"target\"],\n",
    "    validation_data=(validation_df[\"text\"], validation_df[\"target\"]),\n",
    "    epochs=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50484bbc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
