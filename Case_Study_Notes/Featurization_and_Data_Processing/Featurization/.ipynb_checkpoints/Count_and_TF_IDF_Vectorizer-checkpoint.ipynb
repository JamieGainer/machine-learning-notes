{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24c4cd5a",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86b01818",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d2b0f8",
   "metadata": {},
   "source": [
    "By default, punctuation is stripped out and only words longer than 2 letters are counted (via the default regex set by the token_patterns option). All words are first lower-cased (so \"Yes\" and \"yes\" are the same word) via the lowercase option."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b652f15",
   "metadata": {},
   "source": [
    "## CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ccb2d6a",
   "metadata": {},
   "source": [
    "We first initialize a CountVectorizer object, optionally changing the default options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7cebfd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba814bf",
   "metadata": {},
   "source": [
    "We then use \"fit_transform\" to obtain bag of word/ word count vectors for the sentences in our corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16c7c5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_vectors = vectorizer.fit_transform([\"I am happy\", \"Yes I am\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984c52e2",
   "metadata": {},
   "source": [
    "The result is a collection (matrix) of sparse vectors, as for a more realistic corpus, there would be more than 3 words longer than 2 characters.  We can see the counts explicitly by converting this matrix to a dense matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "394d3747",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[1, 1, 0],\n",
       "        [1, 0, 1]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_vectors.todense()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0deab197",
   "metadata": {},
   "source": [
    "And we can see which words are represented by these features using the get_feature_names method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c1c6328",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['am', 'happy', 'yes']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8d6e09",
   "metadata": {},
   "source": [
    "Finally we can use the featurizer to transform sentences in new corpus to word vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "930390c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[1, 1, 1],\n",
       "        [1, 0, 0],\n",
       "        [0, 3, 0],\n",
       "        [0, 1, 1]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.transform([\"Yes, I am the very model of a happy major general\", \n",
    "                      \"I am the very model of a modern major general\",\n",
    "                      \"Happy happy happy\",\n",
    "                      \"Yes, happy\"]).todense()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025c7045",
   "metadata": {},
   "source": [
    "We see that the transform function counts the numbers of \"am\", \"happy\", and \"yes\" in each sentence ignoring capitalization and punctuation.  New words are ignored."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72df9ad8",
   "metadata": {},
   "source": [
    "## TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62602201",
   "metadata": {},
   "source": [
    "We now perform the analogous procedure for the TF-IDF vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44967a98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.57973867, 0.81480247, 0.        ],\n",
       "        [0.57973867, 0.        , 0.81480247]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_vectorizer = TfidfVectorizer()\n",
    "tf_bow_vectors = tf_vectorizer.fit_transform([\"I am happy\", \"Yes I am\"])\n",
    "tf_bow_vectors.todense()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49f9ab5",
   "metadata": {},
   "source": [
    "Following the documentation (https://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction), the TF-IDF values in the rows are  \n",
    "(1) the number of times the word shows up in the given string  \n",
    "(2) times (log(1 + the number of rows) - log(1 + the number of rows wiht the given word) + 1)  \n",
    "(3) with the values in each row normalized to Euclidean length of 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "09eefc08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9999999999999999\n",
      "0.9999999999999999\n"
     ]
    }
   ],
   "source": [
    "for row in tf_bow_vectors.todense().tolist():\n",
    "    total = 0.0\n",
    "    for x in row:\n",
    "        total += x**2\n",
    "    print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f08e60ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[1, 1, 0],\n",
       "        [1, 0, 1]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_vectors.todense()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00488a55",
   "metadata": {},
   "source": [
    "The first word (\"am\") shows up in both words, so the IDF value is 1.  \n",
    "The other words in the vectors only show up in one word, so the IDF value is 1 - log(2) + log(3) $\\approx$ 1.41"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a9387836",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.4054651081081646, 1.4054651037854693)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "1 - np.log(2) + np.log(3), 0.81480247 / 0.57973867"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dc97d19a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.44943642, 0.6316672 , 0.6316672 ],\n",
       "        [1.        , 0.        , 0.        ],\n",
       "        [0.        , 1.        , 0.        ],\n",
       "        [0.        , 0.70710678, 0.70710678]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_vectorizer.transform([\"Yes, I am the very model of a happy major general\", \n",
    "                      \"I am the very model of a modern major general\",\n",
    "                      \"Happy happy happy\",\n",
    "                      \"Yes, happy\"]).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f10acc9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
