{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24c4cd5a",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86b01818",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d2b0f8",
   "metadata": {},
   "source": [
    "By default, punctuation is stripped out and only words longer than 2 letters are counted (via the default regex set by the token_patterns option). All words are first lower-cased (so \"Yes\" and \"yes\" are the same word) via the lowercase option."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b652f15",
   "metadata": {},
   "source": [
    "## Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ccb2d6a",
   "metadata": {},
   "source": [
    "We first initialize a CountVectorizer object, optionally changing the default options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7cebfd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba814bf",
   "metadata": {},
   "source": [
    "We then use \"fit_transform\" to obtain bag of word/ word count vectors for the sentences in our corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "16c7c5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_vectors = vectorizer.fit_transform([\"I am happy\", \"Yes I am\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984c52e2",
   "metadata": {},
   "source": [
    "The result is a collection (matrix) of sparse vectors, as for a more realistic corpus, there would be more than 3 words longer than 2 characters.  We can see the counts explicitly by converting this matrix to a dense matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "394d3747",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[1, 1, 0],\n",
       "        [1, 0, 1]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_vectors.todense()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0deab197",
   "metadata": {},
   "source": [
    "And we can see which words are represented by these features using the get_feature_names method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7c1c6328",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['am', 'happy', 'yes']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8d6e09",
   "metadata": {},
   "source": [
    "Finally we can use the featurizer to transform sentences in new corpus to word vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "930390c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[1, 1, 1],\n",
       "        [1, 0, 0],\n",
       "        [0, 3, 0],\n",
       "        [0, 1, 1]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.transform([\"Yes, I am the very model of a happy major general\", \n",
    "                      \"I am the very model of a modern major general\",\n",
    "                      \"Happy happy happy\",\n",
    "                      \"Yes, happy\"]).todense()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025c7045",
   "metadata": {},
   "source": [
    "We see that the transform function counts the numbers of \"am\", \"happy\", and \"yes\" in each sentence ignoring capitalization and punctuation.  New words are ignored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a44b3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
